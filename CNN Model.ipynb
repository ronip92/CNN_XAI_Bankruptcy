{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score, roc_curve, precision_score, recall_score, f1_score, auc, roc_auc_score  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9813648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Bankruptcy' and 'Non_Bankruptcy' are constants representing the labels\n",
    "Bankruptcy = 1\n",
    "Non_Bankruptcy = 0\n",
    "\n",
    "bankruptcy_images = []\n",
    "bankruptcy_labels = []\n",
    "for filename in os.listdir('FS0/Bankruptcy'):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join('FS0/Bankruptcy', filename)\n",
    "        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224,224))\n",
    "        image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        bankruptcy_images.append(image_array)\n",
    "        bankruptcy_labels.append(Bankruptcy)  # Label for Bankruptcy\n",
    "\n",
    "non_bankruptcy_images = []\n",
    "non_bankruptcy_labels = []\n",
    "for filename in os.listdir('FS0/NonBankruptcy'):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image_path = os.path.join('FS0/NonBankruptcy', filename)\n",
    "        image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224,224))\n",
    "        image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        non_bankruptcy_images.append(image_array)\n",
    "        non_bankruptcy_labels.append(Non_Bankruptcy)  # Label for Non Bankruptcy\n",
    "\n",
    "images = np.array(bankruptcy_images + non_bankruptcy_images)\n",
    "labels = np.array(bankruptcy_labels + non_bankruptcy_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers with dropout for regularization\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output and add dense layers with dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d133bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "avg_accuracy = []\n",
    "avg_recall = []\n",
    "avg_precision = []\n",
    "avg_f1 = []\n",
    "avg_roc_auc = []\n",
    "avg_kappa = []\n",
    "avg_type_ii_error = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skfold.split(X_train, y_train), 1):  \n",
    "    # Split the data into train and test sets for this fold\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    \n",
    "    history = model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test_fold)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_binary)\n",
    "    recall = recall_score(y_test_fold, y_pred_binary)\n",
    "    precision = precision_score(y_test_fold, y_pred_binary)\n",
    "    f1 = f1_score(y_test_fold, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_test_fold, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test_fold, y_pred_binary)\n",
    "    type_ii_error = 1 - recall\n",
    "    \n",
    "    print(f'Fold {fold}:')\n",
    "    print(f'  Accuracy: {accuracy}')\n",
    "    print(f'  Recall: {recall}')\n",
    "    print(f'  Precision: {precision}')\n",
    "    print(f'  F1 Score: {f1}')\n",
    "    print(f'  ROC AUC: {roc_auc}')\n",
    "    print(f'  Kappa: {kappa}')\n",
    "    print(f'  type_ii_error: {type_ii_error}')\n",
    "    print()\n",
    "\n",
    "    # Append metrics for this fold to the lists\n",
    "    avg_accuracy.append(accuracy)\n",
    "    avg_recall.append(recall)\n",
    "    avg_precision.append(precision)\n",
    "    avg_f1.append(f1)\n",
    "    avg_roc_auc.append(roc_auc)\n",
    "    avg_kappa.append(kappa)\n",
    "    avg_type_ii_error.append(type_ii_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8d7d5-3410-4109-bfcc-82feacd9674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(avg_accuracy)\n",
    "avg_recall = np.mean(avg_recall)\n",
    "avg_precision = np.mean(avg_precision)\n",
    "avg_f1 = np.mean(avg_f1)\n",
    "avg_roc_auc = np.mean(avg_roc_auc)\n",
    "avg_kappa = np.mean(avg_kappa)\n",
    "avg_type_ii_error = np.mean(type_ii_error)\n",
    "\n",
    "# Print average metrics\n",
    "print(f'Average Accuracy: {avg_accuracy}')\n",
    "print(f'Average Recall: {avg_recall}')\n",
    "print(f'Average Precision: {avg_precision}')\n",
    "print(f'Average F1 Score: {avg_f1}')\n",
    "print(f'Average ROC AUC: {avg_roc_auc}')\n",
    "print(f'Average Kappa: {avg_kappa}')\n",
    "print(f'Average Type II Error: {avg_type_ii_error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ea8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNNFS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model\n",
    "model = tf.keras.models.load_model('CNNFS.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9fafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
