{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332e6f3-13e1-482c-8641-f0d52041941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf55e5c-3c61-4a80-a769-0d04cc54987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants representing labels\n",
    "Bankruptcy = 1\n",
    "Non_Bankruptcy = 0\n",
    "\n",
    "# Load images\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "            image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            images.append(image_array)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "bankruptcy_images, bankruptcy_labels = load_images_from_folder('FS0/Bankruptcy', Bankruptcy)\n",
    "non_bankruptcy_images, non_bankruptcy_labels = load_images_from_folder('FS0/NonBankruptcy', Non_Bankruptcy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354abd0-c0a4-4613-9d21-183250945a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 1:1 ratio by sampling non-bankruptcy images\n",
    "# Find the minimum size to make sure the dataset is balanced\n",
    "min_size = min(len(bankruptcy_images), len(non_bankruptcy_images))\n",
    "bankruptcy_images = bankruptcy_images[:min_size]\n",
    "bankruptcy_labels = bankruptcy_labels[:min_size]\n",
    "non_bankruptcy_images = non_bankruptcy_images[:min_size]\n",
    "non_bankruptcy_labels = non_bankruptcy_labels[:min_size]\n",
    "\n",
    "# Combine and shuffle the dataset\n",
    "images = np.array(bankruptcy_images + non_bankruptcy_images)\n",
    "labels = np.array(bankruptcy_labels + non_bankruptcy_labels)\n",
    "indices = np.arange(len(labels))\n",
    "np.random.shuffle(indices)\n",
    "images = images[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557f20f8-9164-4174-a682-a8ed7c4d33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229ce53-0b7d-467b-96d7-cc1e42684e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers with dropout for regularization\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output and add dense layers with dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae6c00-5528-4c78-8df7-8d1e533cf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "avg_accuracy = []\n",
    "avg_recall = []\n",
    "avg_precision = []\n",
    "avg_f1 = []\n",
    "avg_roc_auc = []\n",
    "avg_kappa = []\n",
    "avg_type_ii_error = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skfold.split(X_train, y_train), 1):  \n",
    "    # Split the data into train and test sets for this fold\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    \n",
    "    history = model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test_fold)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_binary)\n",
    "    recall = recall_score(y_test_fold, y_pred_binary)\n",
    "    precision = precision_score(y_test_fold, y_pred_binary)\n",
    "    f1 = f1_score(y_test_fold, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_test_fold, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test_fold, y_pred_binary)\n",
    "    type_ii_error = 1 - recall\n",
    "    \n",
    "    print(f'Fold {fold}:')\n",
    "    print(f'  Accuracy: {accuracy}')\n",
    "    print(f'  Recall: {recall}')\n",
    "    print(f'  Precision: {precision}')\n",
    "    print(f'  F1 Score: {f1}')\n",
    "    print(f'  ROC AUC: {roc_auc}')\n",
    "    print(f'  Kappa: {kappa}')\n",
    "    print(f'  type_ii_error: {type_ii_error}')\n",
    "    print()\n",
    "\n",
    "    # Append metrics for this fold to the lists\n",
    "    avg_accuracy.append(accuracy)\n",
    "    avg_recall.append(recall)\n",
    "    avg_precision.append(precision)\n",
    "    avg_f1.append(f1)\n",
    "    avg_roc_auc.append(roc_auc)\n",
    "    avg_kappa.append(kappa)\n",
    "    avg_type_ii_error.append(type_ii_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9041c-2368-462f-82fa-b034c3b4a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(avg_accuracy)\n",
    "avg_recall = np.mean(avg_recall)\n",
    "avg_precision = np.mean(avg_precision)\n",
    "avg_f1 = np.mean(avg_f1)\n",
    "avg_roc_auc = np.mean(avg_roc_auc)\n",
    "avg_kappa = np.mean(avg_kappa)\n",
    "avg_type_ii_error = np.mean(type_ii_error)\n",
    "\n",
    "# Print average metrics\n",
    "print(f'Average Accuracy: {avg_accuracy}')\n",
    "print(f'Average Recall: {avg_recall}')\n",
    "print(f'Average Precision: {avg_precision}')\n",
    "print(f'Average F1 Score: {avg_f1}')\n",
    "print(f'Average ROC AUC: {avg_roc_auc}')\n",
    "print(f'Average Kappa: {avg_kappa}')\n",
    "print(f'Average Type II Error: {avg_type_ii_error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3104da-0721-48a2-9406-929ebe3f69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('CNNFS_balanced_1_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
