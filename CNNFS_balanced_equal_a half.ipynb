{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61cdc2-f2b3-4968-b70f-c350d4552591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, cohen_kappa_score\n",
    "from sklearn.utils import resample, class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614b0ae-90a7-4ba1-ac21-8f6661b5b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants representing labels\n",
    "Bankruptcy = 1\n",
    "Non_Bankruptcy = 0\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "            image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            images.append(image_array)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Load images\n",
    "bankruptcy_images, bankruptcy_labels = load_images_from_folder('FS0/Bankruptcy', Bankruptcy)\n",
    "non_bankruptcy_images, non_bankruptcy_labels = load_images_from_folder('FS0/NonBankruptcy', Non_Bankruptcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561ae6c-c669-4b5d-8d13-da5c76c49828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for bankruptcy images\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_bankruptcy_images = []\n",
    "augmented_bankruptcy_labels = []\n",
    "\n",
    "for image in bankruptcy_images:\n",
    "    augmented_bankruptcy_images.append(image)  # Keep original image\n",
    "    augmented_bankruptcy_labels.append(Bankruptcy)\n",
    "    image = image.reshape((1,) + image.shape)\n",
    "    for _ in range(1):  # Generate one additional image for each original\n",
    "        batch = next(data_gen.flow(image, batch_size=1))\n",
    "        augmented_image = batch[0]\n",
    "        augmented_bankruptcy_images.append(augmented_image)\n",
    "        augmented_bankruptcy_labels.append(Bankruptcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463590ea-db0b-4cfe-be10-2a5c48d28d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample Non-Bankruptcy Images to half\n",
    "non_bankruptcy_images_resampled, non_bankruptcy_labels_resampled = resample(\n",
    "    non_bankruptcy_images,\n",
    "    non_bankruptcy_labels,\n",
    "    replace=False,\n",
    "    n_samples=len(non_bankruptcy_images) // 2,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905a97a-1d7c-4141-a658-d088e1236374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "images_combined = np.concatenate((augmented_bankruptcy_images, non_bankruptcy_images_resampled))\n",
    "labels_combined = np.concatenate((augmented_bankruptcy_labels, non_bankruptcy_labels_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a866d5-07ba-4be6-a88a-66e590718c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_combined, labels_combined, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f29c2-ca3c-4b55-9f89-af9810859a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers with dropout for regularization\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output and add dense layers with dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c093a0-a717-4c2c-aa43-47edd2e59a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7775789-8c4b-4bb5-b4f2-26fe16b3b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "avg_accuracy = []\n",
    "avg_recall = []\n",
    "avg_precision = []\n",
    "avg_f1 = []\n",
    "avg_roc_auc = []\n",
    "avg_kappa = []\n",
    "avg_type_ii_error = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skfold.split(X_train, y_train), 1):  \n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    # Train the model with class weights\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold, \n",
    "        epochs=10, \n",
    "        batch_size=32, \n",
    "        validation_split=0.2, \n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test_fold)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_binary)\n",
    "    recall = recall_score(y_test_fold, y_pred_binary)\n",
    "    precision = precision_score(y_test_fold, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_test_fold, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_test_fold, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test_fold, y_pred_binary)\n",
    "    type_ii_error = 1 - recall\n",
    "    \n",
    "    # Append metrics\n",
    "    avg_accuracy.append(accuracy)\n",
    "    avg_recall.append(recall)\n",
    "    avg_precision.append(precision)\n",
    "    avg_f1.append(f1)\n",
    "    avg_roc_auc.append(roc_auc)\n",
    "    avg_kappa.append(kappa)\n",
    "    avg_type_ii_error.append(type_ii_error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8492ca6d-dd1e-4a3c-a4d0-3aefdf3c79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print average metrics\n",
    "avg_accuracy = np.mean(avg_accuracy)\n",
    "avg_recall = np.mean(avg_recall)\n",
    "avg_precision = np.mean(avg_precision)\n",
    "avg_f1 = np.mean(avg_f1)\n",
    "avg_roc_auc = np.mean(avg_roc_auc)\n",
    "avg_kappa = np.mean(avg_kappa)\n",
    "avg_type_ii_error = np.mean(avg_type_ii_error)\n",
    "\n",
    "print(f'Average Accuracy: {avg_accuracy}')\n",
    "print(f'Average Recall: {avg_recall}')\n",
    "print(f'Average Precision: {avg_precision}')\n",
    "print(f'Average F1 Score: {avg_f1}')\n",
    "print(f'Average ROC AUC: {avg_roc_auc}')\n",
    "print(f'Average Kappa: {avg_kappa}')\n",
    "print(f'Average Type II Error: {avg_type_ii_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c04053-8a72-45b2-91ef-f79dd321483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('CNNFS_balanced_equal_a half.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
