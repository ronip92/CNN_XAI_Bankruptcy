{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b3cb2-b975-45cc-8705-2998f33c0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score, roc_curve, precision_score, recall_score, f1_score, auc, roc_auc_score  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7cf178-f779-45dd-8410-d7e933b3c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants representing labels\n",
    "Bankruptcy = 1\n",
    "Non_Bankruptcy = 0\n",
    "\n",
    "# Load images\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "            image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            images.append(image_array)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "bankruptcy_images, bankruptcy_labels = load_images_from_folder('FS0/Bankruptcy', Bankruptcy)\n",
    "non_bankruptcy_images, non_bankruptcy_labels = load_images_from_folder('FS0/NonBankruptcy', Non_Bankruptcy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254242f2-4456-4fd3-933e-632f84b867e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for bankruptcy images to double their count\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_bankruptcy_images = []\n",
    "augmented_bankruptcy_labels = []\n",
    "\n",
    "for image in bankruptcy_images:\n",
    "    augmented_bankruptcy_images.append(image)  # Original image\n",
    "    augmented_bankruptcy_labels.append(Bankruptcy)\n",
    "    image = image.reshape((1,) + image.shape)  # Reshape to (1, 224, 224, 3) for data_gen\n",
    "    i = 0\n",
    "    for batch in data_gen.flow(image, batch_size=1):\n",
    "        augmented_image = batch[0]\n",
    "        augmented_bankruptcy_images.append(augmented_image)\n",
    "        augmented_bankruptcy_labels.append(Bankruptcy)\n",
    "        i += 1\n",
    "        if i == 1:  # Generate one additional image for each original to double the count\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b339cde-1ce5-49a9-88c0-9dc5dfc1bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the length of augmented bankruptcy images is up to twice the original count\n",
    "non_bankruptcy_size = len(non_bankruptcy_images)\n",
    "desired_bankruptcy_size = 2 * non_bankruptcy_size\n",
    "augmented_bankruptcy_images = augmented_bankruptcy_images[:desired_bankruptcy_size]\n",
    "augmented_bankruptcy_labels = augmented_bankruptcy_labels[:desired_bankruptcy_size]\n",
    "\n",
    "# Combine and shuffle the dataset\n",
    "images = np.array(augmented_bankruptcy_images + non_bankruptcy_images)\n",
    "labels = np.array(augmented_bankruptcy_labels + non_bankruptcy_labels)\n",
    "indices = np.arange(len(labels))\n",
    "np.random.shuffle(indices)\n",
    "images = images[indices]\n",
    "labels = labels[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980275b-1cce-45f3-b3cf-379ffe3fde8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c47b1f5-d205-4b35-bbfe-47525018928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers with dropout for regularization\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output and add dense layers with dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea393da-689f-4683-9043-16da38b22b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "avg_accuracy = []\n",
    "avg_recall = []\n",
    "avg_precision = []\n",
    "avg_f1 = []\n",
    "avg_roc_auc = []\n",
    "avg_kappa = []\n",
    "avg_type_ii_error = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skfold.split(X_train, y_train), 1):  \n",
    "    # Split the data into train and test sets for this fold\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    \n",
    "    history = model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test_fold)\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Calculate metrics for this fold\n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_binary)\n",
    "    recall = recall_score(y_test_fold, y_pred_binary)\n",
    "    precision = precision_score(y_test_fold, y_pred_binary)\n",
    "    f1 = f1_score(y_test_fold, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_test_fold, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test_fold, y_pred_binary)\n",
    "    type_ii_error = 1 - recall\n",
    "    \n",
    "    print(f'Fold {fold}:')\n",
    "    print(f'  Accuracy: {accuracy}')\n",
    "    print(f'  Recall: {recall}')\n",
    "    print(f'  Precision: {precision}')\n",
    "    print(f'  F1 Score: {f1}')\n",
    "    print(f'  ROC AUC: {roc_auc}')\n",
    "    print(f'  Kappa: {kappa}')\n",
    "    print(f'  type_ii_error: {type_ii_error}')\n",
    "    print()\n",
    "\n",
    "    # Append metrics for this fold to the lists\n",
    "    avg_accuracy.append(accuracy)\n",
    "    avg_recall.append(recall)\n",
    "    avg_precision.append(precision)\n",
    "    avg_f1.append(f1)\n",
    "    avg_roc_auc.append(roc_auc)\n",
    "    avg_kappa.append(kappa)\n",
    "    avg_type_ii_error.append(type_ii_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb3604-b101-45c8-bb27-ec954c4ea545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(avg_accuracy)\n",
    "avg_recall = np.mean(avg_recall)\n",
    "avg_precision = np.mean(avg_precision)\n",
    "avg_f1 = np.mean(avg_f1)\n",
    "avg_roc_auc = np.mean(avg_roc_auc)\n",
    "avg_kappa = np.mean(avg_kappa)\n",
    "avg_type_ii_error = np.mean(type_ii_error)\n",
    "\n",
    "# Print average metrics\n",
    "print(f'Average Accuracy: {avg_accuracy}')\n",
    "print(f'Average Recall: {avg_recall}')\n",
    "print(f'Average Precision: {avg_precision}')\n",
    "print(f'Average F1 Score: {avg_f1}')\n",
    "print(f'Average ROC AUC: {avg_roc_auc}')\n",
    "print(f'Average Kappa: {avg_kappa}')\n",
    "print(f'Average Type II Error: {avg_type_ii_error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77501795-5a29-434d-ad39-e97b60d4059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('CNNFS_balanced_2_all_nonbankrupt.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
